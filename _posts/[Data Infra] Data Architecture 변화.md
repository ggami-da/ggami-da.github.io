---
layout: post
title: Flake it till you make it
subtitle: Excerpt from Soulshaping by Jeff Brown
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [books, test]
author: Sharon Smith and Barry Simpson
---

## 데이터 아키텍쳐의 변화

데이터 아키텍쳐는 Hadoop이 나오기 이전과 이후로 나누어 볼 수 있습니다.
과거에는 Operation Data Plane에서 분석을 위해 정보계로 옮기는 작업을 많이 진행하였습니다.
보통은 새벽 시간에 Shell 및 ETL Tool을 활용하여 데이터를 옮기고 데이터 마트 구성 및 시각화를 위한 파이프라인을 구성하였습니다.
만약 성능이 나지 않으면 DBA가 DB Tuning을 진행하였습니다.

그런데 Data Warehouse에 테이블이 많이지게 되면서 같은 컬럼이지만 다른 이름으로 쓰는 경우가 많아졌고 그러다 보니 이를 관리하기 위한 Meta Data System이 나오게 되었습니다. 그리고 데이터 분석가가 Data Model을 만들고 이를 기반으로 Data Mart를 추가하고 이를 통해 시각화하였습니다.

그럼 Meta Data System은 무엇일까요?
데이터를 위한 데이터 정보라고 생각할 수 있습니다. 

그 이후에 Hadoop이 등장하게 되면서 Hadoop 기반으로 기술적인 부분이 출현하게 되었습니다. 그 기반은 구글이라는 검색 엔진이 나오게 되면서 검색에 활용한 데이터를 저장하기 위한 저장소를 만들기 시작하였고 이를 기반으로 HDFS라는 파일 시스템이 나오게 되었고 단일 시스템이 아닌 병렬 시스템이 등장하게 되었습니다. 

이 시점부터 개인에 대한 여러 데이터들이 쌓이기 시작하였고 비정형 및 반정형 데이터들이 나오기 시작하였습니다. (Xml, CSV etc)
이를 기반으로 기존의 Operation Data에서 비정형, 반정형 데이터를 저장할 수 있도록 데이터 파이프라인의 변화가 생기기 시작하였습니다. 이 때부터 DataLake 즉, Hadoop, Hive, Spark 등의 오픈 소스가 생겨나기 시작하였습니다. 그러나 Hadoop은 데이터를 많이 저장하지만 관리적인 요소가 단점으로 부각되었습니다. 

Hadoop을 기반으로 여러 오픈 소스들이 나오기 시작하였고 그 중 가장 핵심적인 것이 HDFS (Hadoop Distributed File System) 분산 시스템이 나왔고 Map Reduce를 통해 분산 시스템에서 분석할 수 있도록 되었습니다. 하지만 Java 기반이기 떄문에 단순히 Where 구문을 추가할 수 있는 수준이였고 이를 보완하기 위해서 Hive (Sql Query)가 나오게 되었습니다. 다만 Hive의 큰 단점으로 느린 속도가 있었습니다. 이러한 느린 속도라는 약점을 파고드는 오픈 소스들이 나오게 되었고 그 중 유명한 것이 Spark입니다. 이후 Spark이 시장을 주도하게 되었습니다.

Spark은 아래와 같은 장점이 있습니다.

1. 분삭 데이터 처리 : 메모리에 캐시하여 무척 빠른 속도
2. 실시간 스트리밍 처리 
3. Java, Scala, Python, R 등의 여러 언어를 지원
4. 다양한 워크로드 지원 : SQL 쿼리를 통한 분석, 머신 러닝 알고리즘 학습 및 실행, 실시간 분석, 그래프 처리 등 다양한 작업을 효과적으로 처리

Spark은 또한 여러 서버 (노드)를 통해서 분산 처리르 할 수 있는 것 뿐아니라 그 과정 중 특정 서버가 Failed가 나더라도 저장된 부분을 다른 서버로 옮겨 데이터 손실이 없다는 것이 가장 큰 장점입니다.

데이터 레이크 이후에 비정형, 반정형이 많아지는 환경이 되었고 모든 비지니스에 대해서 활용하고자 하기 시작하였고 에코 시스템에서 분석하던 방식이 데이터 레이크하우스가 나오게 되었습니다. 그 중 가장 큰 변화가 클라우드 (빅쿼리)입니다. 데이터 레이크 하우스 클라우드의 분석 환경이라고 볼 수 있음 (메타, 캐쉬, 인덱싱이 모두 클라우드에서 자동적으로 지원)

TCO (Total Cost of Ownership) 총 소유 비용 분석을 하게 됨 
AWS는 아래와 같이 총 소유 비용을 조절할 수 있음

1. 적절한 용량 산정 (스케일 인 - 아웃)
2. 탄력적 아키텍쳐 
3. 구매 옵션 (미리 장비를 구매하면 할인)
4. 스토리지 클래스 

Compute And Storage 분리가 가장 중요한 핵심입니다.
이를 통해서 확장성이 뛰어난 플랫폼을 구축할 수 있습니다.

여러 위치의 다양한 소스로부터 발생한 데이터를 유연하게 저장 가능한 저장 플랫폼을 논리적 혹은 가상의 최적화된 환경으로 쉽고 효과적으로 분석이 가능합니다. 

보통은 레이어 형식으로 되어 있는데 아래와 같이 분리가 가능합니다.

1. CPU와 Storage 용량의 독립적인 확장 : CPU가 부족하면 CPU만 늘리고 Storage가 부족하면 Storage만 늘릴 수 있다.
2. 단일화된 중앙 집중형 데이터 보관 : 메타 정보 등의 핵심적인 부분은 중앙 집중형으로 데이터 보관이 가능해집니다. 
3. Agile 어플리케이션 개발 지원 : 서로 분리가 되어 있기 떄문에 데이터가 어디에 저장이 되었는지 알고만 있으면 쉽게 접근해서 여러 새롭게 나오는 오픈 소스를 적용해서 분석할 수 있습니다.
4. 하이브리드 클라우드 구현 : 많은 데이터들을 Object Storage에 저장이 되어 있는데 분석에 활용되어 있지 않은 데이터에 대한 비용을 줄이기 위한 방법을 구상하다가 하이브리드가 나왔음. 분석하는 경우에만 S3로 데이터를 내려서 분석을 진행함.

Spot Instance는 모든 클라우드 서비스가 가지고 있지만 각 Zone안에 있는 유휴 자원을 아주 싸게 경매를 통해서 이용할 수 있습니다.

HDFS로 S3를 사용한다면 

1. 컴퓨팅 노드와 데이터 노르를 구분해서 운영 가능
2. 클러스터를 종료 후 다시 클러스터를 구상해도 기존 데이터를읽을 수 있다.
3. HDFS 확장을 신경쓰지 않아도 된다. 


--------------------------------------------------------

파이프라인이란?

컴퓨터 과학에서 파이프라인은 한 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태로 연결되는 구조를 말합니다. 최근에는 여러 개인에 따라서 역할을 맡고 End-To-End로 구성하고 있습니다.

데이터 파이프라인은 구성하는데 있어서 중요하게 생각해볼 부분은 아래 8가지가 있습니다.

1. 회사 내 데이터 요구사항에 대해서 빠르게 대응할 수 있어야 합니다.
2. 지속적이고 에러가 없어야 합니다.
3. 시스템적으로 발생하는 문제에 대해서 유연한 Scability 해야 합니다.
4. 스케일 인-아웃이 자유로워야 합니다.
5. 이벤트성 데이터가 많더라도 그러한 부하도 처리가 가능해야 합니다.
6. 데이터 쌓이는 공간에 문제가 없어야 합니다.
7. 수집된 데이터의 유연성을 고려해야 합니다.
8. 쉽게 분석 데이터 포맷을 만들어야 합니다. 

<사진>

하나씩 설명을 해보면 다음과 같습니다.
인터넷을 통해서 여러 파일이 Raw 데이터로 저장이 됩니다. 이러한 Raw 데이터를 API GateWay, Kinesis Streams, Kinesis Firehose를 통해서 외부 데이터를 내부 서비스로 연결할 수 있습니다. 

이렇게 Raw 데이터가 저장이 된다면 배치 프로세스 엔진, 실시간 프로세스 엔진을 구성할 수 있습니다. 
배치 프로세스를 진행할 때 Spark를 사용하고 Spark은 AWS DMS에서 운영이 되도록 할 수 있습니다. 이 경우에는 일별 데이터가 쌓이게 됩니다. 일 데이터를 많이 쌓게 되면 일, 주, 월, 분기, 년 데이터를 분석할 수 있게 됩니다. 

이러한 데이터를 가지고 SageMaker를 통해서 분석 모델을 구축할 수 있고 AWS Elastic Search, Dynamo DB, RDS, Redshift (MPP)를 활용하여 데이터를 적재할 수 있습니다. 

이러한 파이프 라인을 운영하기 위해서 Mate 데이터를 저장하기 위해서 Data Catalog(Glue)를 구성할 수 있습니다.

* Kinesis Firehose는 Queue에 데이터를 저장하고 해당 데이터를 쉽게 내릴 수 있도록 하는 서비스
* Pinpoin는 메세지, 메일 등의 마케팅 정보를 제공하기 위한 서비스
* DMS의 경우에는 데이터를 데이터 레이크에 전체 데이터를 옮겨야할 경우에 도와주는 서비스

AWS S3는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 서비스 입니다.

버킷 : AWS S3에 저장된 객체에 대한 컨테이너이며 모든 객체는 어떤 버킷에 포함되게 됩니다. (윈도우 폴더)
객체 : AWS S3에 저장되는 기본 개체이며 객체는 객체 데이타와 메타 데이터로 구성됩니다.
키 : 버킷 매 객체의 고유한 식별자이며 버킷 내 모든 객체는 정확히 하나의 키를 갖습니다. 
    버킷, 키, 및 버전 ID 조합이 각 객체를 고유하게 식별하기 때문에 S3에서는 객체 자체 사이의 기본 데이터 맵으로 간주할 수 있습니다.

AWS RDS는 클라우드에서 관계형 데이터베이스를 쉽게 설치 및 운영할 수 있는 웹 서비스 입니다.

1. 클라우드에서 관계형 데이터베이스를 간편하게 설정 및 운영할 수 있습니다.
2. 하드웨어 프로비저닝, 데이터베이스 설정, 패치 등 시간 소모적 작업을 자동화할 수 있습니다.